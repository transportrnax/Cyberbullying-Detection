{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T13:32:03.932572Z",
     "start_time": "2024-12-16T13:32:03.898709Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "import re, string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "#from sklearn.metrics import plot_precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20b45eb37d97f1d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T13:23:59.754807Z",
     "start_time": "2024-12-16T13:23:59.597513Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the preprocessed data (assuming it's saved in \"final_preprocessed_data.csv\")\n",
    "data = pd.read_csv(\"final_preprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7add06496748683b",
   "metadata": {},
   "source": [
    "## TF-IDF feature extraction + dimensionality reduction + normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "403677e5d4641eea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T13:25:10.855192Z",
     "start_time": "2024-12-16T13:24:01.189915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction, PCA, and normalization complete. Data saved to final_features_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where 'Message' column has NaN values\n",
    "data = data.dropna(subset=['Message'])\n",
    "\n",
    "# TF-IDF feature extraction\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Set the maximum number of features\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(data['Message'])\n",
    "\n",
    "# PCA for dimensionality reduction\n",
    "pca = PCA(n_components=100)  # Reduce the features to 100 dimensions\n",
    "X_pca = pca.fit_transform(X_tfidf.toarray())  # Convert the sparse matrix to an array for PCA\n",
    "\n",
    "# Normalization\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_pca)\n",
    "\n",
    "# Combine the processed features with the labels\n",
    "final_data = pd.DataFrame(X_scaled)\n",
    "final_data['label'] = data['label'].values\n",
    "\n",
    "# Save the final data to a CSV file\n",
    "final_data.to_csv(\"final_features_data.csv\", index=False)\n",
    "print(\"Feature extraction, PCA, and normalization complete. Data saved to final_features_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e58b57c1e1edeab2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-16T13:33:51.312171Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Average Accuracy: 0.8009017622127264\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.91      0.83     13561\n",
      "           1       0.88      0.68      0.77     12211\n",
      "\n",
      "    accuracy                           0.80     25772\n",
      "   macro avg       0.82      0.80      0.80     25772\n",
      "weighted avg       0.82      0.80      0.80     25772\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83     13845\n",
      "           1       0.86      0.68      0.76     11926\n",
      "\n",
      "    accuracy                           0.80     25771\n",
      "   macro avg       0.81      0.79      0.79     25771\n",
      "weighted avg       0.81      0.80      0.80     25771\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.83     13592\n",
      "           1       0.86      0.69      0.77     12179\n",
      "\n",
      "    accuracy                           0.80     25771\n",
      "   macro avg       0.81      0.80      0.80     25771\n",
      "weighted avg       0.81      0.80      0.80     25771\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83     13879\n",
      "           1       0.85      0.68      0.76     11892\n",
      "\n",
      "    accuracy                           0.80     25771\n",
      "   macro avg       0.81      0.79      0.79     25771\n",
      "weighted avg       0.81      0.80      0.80     25771\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83     13653\n",
      "           1       0.86      0.69      0.77     12118\n",
      "\n",
      "    accuracy                           0.80     25771\n",
      "   macro avg       0.81      0.80      0.80     25771\n",
      "weighted avg       0.81      0.80      0.80     25771\n",
      "\n",
      "Logistic Regression Average Accuracy: 0.8046035581613828\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83     13561\n",
      "           1       0.85      0.72      0.78     12211\n",
      "\n",
      "    accuracy                           0.81     25772\n",
      "   macro avg       0.82      0.80      0.81     25772\n",
      "weighted avg       0.81      0.81      0.81     25772\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83     13845\n",
      "           1       0.83      0.72      0.77     11926\n",
      "\n",
      "    accuracy                           0.80     25771\n",
      "   macro avg       0.81      0.80      0.80     25771\n",
      "weighted avg       0.81      0.80      0.80     25771\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83     13592\n",
      "           1       0.84      0.72      0.78     12179\n",
      "\n",
      "    accuracy                           0.80     25771\n",
      "   macro avg       0.81      0.80      0.80     25771\n",
      "weighted avg       0.81      0.80      0.80     25771\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83     13879\n",
      "           1       0.83      0.72      0.77     11892\n",
      "\n",
      "    accuracy                           0.80     25771\n",
      "   macro avg       0.81      0.80      0.80     25771\n",
      "weighted avg       0.81      0.80      0.80     25771\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83     13653\n",
      "           1       0.84      0.72      0.78     12118\n",
      "\n",
      "    accuracy                           0.80     25771\n",
      "   macro avg       0.81      0.80      0.80     25771\n",
      "weighted avg       0.81      0.80      0.80     25771\n",
      "\n",
      "Random Forest Average Accuracy: 0.8932451526446957\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90     13561\n",
      "           1       0.90      0.88      0.89     12211\n",
      "\n",
      "    accuracy                           0.90     25772\n",
      "   macro avg       0.90      0.89      0.90     25772\n",
      "weighted avg       0.90      0.90      0.90     25772\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90     13845\n",
      "           1       0.89      0.88      0.88     11926\n",
      "\n",
      "    accuracy                           0.89     25771\n",
      "   macro avg       0.89      0.89      0.89     25771\n",
      "weighted avg       0.89      0.89      0.89     25771\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90     13592\n",
      "           1       0.90      0.88      0.89     12179\n",
      "\n",
      "    accuracy                           0.90     25771\n",
      "   macro avg       0.90      0.89      0.89     25771\n",
      "weighted avg       0.90      0.90      0.90     25771\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90     13879\n",
      "           1       0.89      0.88      0.88     11892\n",
      "\n",
      "    accuracy                           0.89     25771\n",
      "   macro avg       0.89      0.89      0.89     25771\n",
      "weighted avg       0.89      0.89      0.89     25771\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90     13653\n",
      "           1       0.89      0.88      0.88     12118\n",
      "\n",
      "    accuracy                           0.89     25771\n",
      "   macro avg       0.89      0.89      0.89     25771\n",
      "weighted avg       0.89      0.89      0.89     25771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Labels\n",
    "y = final_data['label']  # Extract labels\n",
    "\n",
    "# Features (X) - Exclude the 'label' column from the features\n",
    "X = final_data.drop('label', axis=1)  # Features without the label\n",
    "\n",
    "# Initialize classifiers\n",
    "svm = SVC(kernel='linear')  # Support Vector Machine with linear kernel\n",
    "lr = LogisticRegression(max_iter=1000)  # Logistic Regression\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)  # Random Forest\n",
    "\n",
    "# Initialize KFold cross-validator\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold cross-validation\n",
    "\n",
    "# Function to evaluate a model using KFold\n",
    "def evaluate_model(model, X, y, kf):\n",
    "    accuracy_scores = []\n",
    "    classification_reports = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]  # Use .iloc for DataFrame indexing\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]  # Ensure labels are in the same format\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        accuracy_scores.append(accuracy_score(y_test, predictions))\n",
    "        classification_reports.append(classification_report(y_test, predictions))  # Print the string report\n",
    "    \n",
    "    avg_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "    avg_classification_report = classification_reports  # List of classification reports from each fold\n",
    "\n",
    "    return avg_accuracy, avg_classification_report\n",
    "\n",
    "# Evaluate using SVM\n",
    "svm_accuracy, svm_report = evaluate_model(svm, X, y, kf)\n",
    "print(\"SVM Average Accuracy:\", svm_accuracy)\n",
    "print(\"SVM Classification Report:\\n\", \"\\n\".join(svm_report))  # Print each fold's report\n",
    "\n",
    "# Evaluate using Logistic Regression\n",
    "lr_accuracy, lr_report = evaluate_model(lr, X, y, kf)\n",
    "print(\"Logistic Regression Average Accuracy:\", lr_accuracy)\n",
    "print(\"Logistic Regression Classification Report:\\n\", \"\\n\".join(lr_report))  # Print each fold's report\n",
    "\n",
    "# Evaluate using Random Forest\n",
    "rf_accuracy, rf_report = evaluate_model(rf, X, y, kf)\n",
    "print(\"Random Forest Average Accuracy:\", rf_accuracy)\n",
    "print(\"Random Forest Classification Report:\\n\", \"\\n\".join(rf_report))  # Print each fold's report\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
